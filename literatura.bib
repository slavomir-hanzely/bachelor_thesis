@article{zhluky_lukacek,
	title = {Použitie metód analýzy zhlukov na konštrukciu návrhov experimentov},
	language = {sk},
	note = {Diplomová práca, FMFI UK, Bratislava, 2017},
	author = {Lukáček, Viktor and Harman, Radoslav}
}

@article{spheres_harman,
	title = {On decompositional algorithms for uniform sampling from n-spheres and n-balls},
	volume = {101},
	issn = {0047259X},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0047259X10001211},
	doi = {10.1016/j.jmva.2010.06.002},
	abstract = {We describe a universal conditional distribution method for uniform sampling from nspheres and n-balls, based on properties of a family of radially symmetric multivariate distributions. The method provides us with a unifying view on several known algorithms as well as enabling us to construct novel variants. We give a numerical comparison of the known and newly proposed algorithms for dimensions 5, 6 and 7.},
	language = {en},
	number = {10},
	urldate = {2018-11-19},
	journal = {Journal of Multivariate Analysis},
	author = {Harman, Radoslav and Lacko, Vladimír},
	month = nov,
	year = {2010},
	pages = {2297--2304},
	file = {Harman and Lacko - 2010 - On decompositional algorithms for uniform sampling.pdf:/home/slavo/Zotero/storage/9UE74NEY/Harman and Lacko - 2010 - On decompositional algorithms for uniform sampling.pdf:application/pdf}
}

@article{ellipsoids_ball,
	title = {Ellipsoids of maximal volume in convex bodies},
	url = {http://arxiv.org/abs/math/9201217},
	abstract = {The largest discs contained in a regular tetrahedron lie in its faces. The proof is closely related to the theorem of Fritz John characterising ellipsoids of maximal volume contained in convex bodies.},
	urldate = {2019-04-25},
	journal = {arXiv:math/9201217},
	author = {Ball, Keith},
	month = sep,
	year = {1990},
	note = {arXiv: math/9201217},
	keywords = {52A, Mathematics - Functional Analysis, Mathematics - Metric Geometry},
	file = {arXiv\:math/9201217 PDF:/home/slavo/Zotero/storage/3ZM7TQAB/Ball - 1990 - Ellipsoids of maximal volume in convex bodies.pdf:application/pdf;arXiv.org Snapshot:/home/slavo/Zotero/storage/UHMB5L6N/9201217.html:text/html}
}

@article{complexity_khachiyan,
	title = {On the complexity of approximating the maximal inscribed ellipsoid for a polytope},
	volume = {61},
	issn = {1436-4646},
	url = {https://doi.org/10.1007/BF01582144},
	doi = {10.1007/BF01582144},
	abstract = {We give a new polynomial bound on the complexity of approximating the maximal inscribed ellipsoid for a polytope.},
	language = {en},
	number = {1},
	urldate = {2019-02-04},
	journal = {Mathematical Programming},
	author = {Khachiyan, Leonid G. and Todd, Michael J.},
	month = aug,
	year = {1993},
	keywords = {computational complexity, Maximal inscribed ellipsoid, maximal inscribed paraboloid, path-following Newton's method},
	pages = {137--159},
	file = {Submitted Version:/home/slavo/Zotero/storage/CMAA5IJU/Khachiyan and Todd - 1993 - On the complexity of approximating the maximal ins.pdf:application/pdf}
}

@article{random_may,
	title = {Random polytopes: {Their} definition, generation and aggregate properties},
	volume = {24},
	issn = {1436-4646},
	shorttitle = {Random polytopes},
	url = {https://doi.org/10.1007/BF01585093},
	doi = {10.1007/BF01585093},
	abstract = {The definition of random polytope adopted in this paper restricts consideration to those probability measures satisfying two properties. First, the measure must induce an absolutely continuous distribution over the positions of the bounding hyperplanes of the random polytope; and second, it must result in every point in the space being equally as likely as any other point of lying within the random polytope. An efficient Monte Carlo method for their computer generation is presented together with analytical formulas characterizing their aggregate properties. In particular, it is shown that the expected number of extreme points for such random polytopes increases monotonically in the number of constraints to the limiting case of a polytope topologically equivalent to a hypercube. The implied upper bound of 2 n wheren is the dimensionality of the space is significantly less than McMullen's attainable bound on the maximal number of vertices even for a moderate number of constraints.},
	language = {en},
	number = {1},
	urldate = {2019-02-05},
	journal = {Mathematical Programming},
	author = {May, Jerrold H. and Smith, Robert L.},
	month = dec,
	year = {1982},
	keywords = {Aggregate Polytope Properties, Linear Programming, Problem Generation, Random Polytopes},
	pages = {39--54}
}

@article{metropolis-hastings_chib,
	title = {Understanding the {Metropolis}-{Hastings} {Algorithm}},
	volume = {49},
	issn = {0003-1305},
	url = {https://amstat.tandfonline.com/doi/abs/10.1080/00031305.1995.10476177},
	doi = {10.1080/00031305.1995.10476177},
	abstract = {We provide a detailed, introductory exposition of the Metropolis-Hastings algorithm, a powerful Markov chain method to simulate multivariate distributions. A simple, intuitive derivation of this method is given along with guidance on implementation. Also discussed are two applications of the algorithm, one for implementing acceptance-rejection sampling when a blanketing function is not available and the other for implementing the algorithm with block-at-a-time scans. In the latter situation, many different algorithms, including the Gibbs sampler, are shown to be special cases of the Metropolis-Hastings algorithm. The methods are illustrated with examples.},
	number = {4},
	urldate = {2018-11-18},
	journal = {The American Statistician},
	author = {Chib, Siddhartha and Greenberg, Edward},
	month = nov,
	year = {1995},
	keywords = {metropolis-hastings},
	pages = {327--335},
	file = {Snapshot:/home/slavo/Zotero/storage/JWUCKJD8/00031305.1995.html:text/html;Submitted Version:/home/slavo/Zotero/storage/MRQ3PUK6/Chib and Greenberg - 1995 - Understanding the Metropolis-Hastings Algorithm.pdf:application/pdf}
}

@article{hit-and-run_chen,
	title = {General {Hit}-and-{Run} {Monte} {Carlo} sampling for evaluating multidimensional integrals},
	volume = {19},
	issn = {0167-6377},
	url = {http://www.sciencedirect.com/science/article/pii/0167637796000302},
	doi = {10.1016/0167-6377(96)00030-2},
	abstract = {We elaborate on the Hit-and-Run sampler, a Monte Carlo approach that estimates the value of a high-dimensional integral with integrand h(x)f(x) by sampling from a time-reversible Markov chain over the suport of the density f. The Markov chain transitions are defined by choosing a random direction and then moving to a new point x whose likelihood depends on f in that direction. The serially dependent observations of h(xi) are averaged to estimate the integral. The sampler applies directly to f being a nonnegative function with finite integral. We generalize the convergence results of Belisle et al. [3] to unbounded regions and to unbounded integrands. Here convergence is of the point estimator to the value of the integral; this convergence is based on convergence in distribution of realizations to their limiting distribution f. An important application is determining properties of Bayesan posterior distributions. Here f is proportional to the posterior density and h is chosen to indicate the property being estimated. Typical properties include means, variances, correlations, probabilities of regions, and predictive densities.},
	number = {4},
	urldate = {2018-11-21},
	journal = {Operations Research Letters},
	author = {Chen, Ming-Hui and Schmeiser, Bruce W.},
	month = oct,
	year = {1996},
	keywords = {Bayesian posterior distribution, Gibbs sampler, Markov chain Monte Carlo, Metropolis's method, Simulation},
	pages = {161--169},
	file = {ScienceDirect Full Text PDF:/home/slavo/Zotero/storage/R4LBXWP3/Chen and Schmeiser - 1996 - General Hit-and-Run Monte Carlo sampling for evalu.pdf:application/pdf;ScienceDirect Snapshot:/home/slavo/Zotero/storage/NL8DSYCQ/0167637796000302.html:text/html}
}

@article{rex_harman,
	title = {A {Randomized} {Exchange} {Algorithm} for {Computing} {Optimal} {Approximate} {Designs} of {Experiments}},
	url = {http://arxiv.org/abs/1801.05661},
	abstract = {We propose a class of subspace ascent methods for computing optimal approximate designs that covers both existing as well as new and more efficient algorithms. Within this class of methods, we construct a simple, randomized exchange algorithm (REX). Numerical comparisons suggest that the performance of REX is comparable or superior to the performance of state-of-the-art methods across a broad range of problem structures and sizes. We focus on the most commonly used criterion of D-optimality that also has applications beyond experimental design, such as the construction of the minimum volume ellipsoid containing a given set of data-points. For D-optimality, we prove that the proposed algorithm converges to the optimum. We also provide formulas for the optimal exchange of weights in the case of the criterion of A-optimality. These formulas enable one to use REX for computing A-optimal and I-optimal designs.},
	urldate = {2018-12-02},
	journal = {to appear in: Journal of the American Statistical Associaition, 2019},
	author = {Harman, Radoslav and Filová, Lenka and Richtárik, Peter},
	month = jan,
	year = {2018},
	note = {arXiv: 1801.05661},
	keywords = {62K05, 90C25, Statistics - Computation},
	annote = {Comment: 23 pages, 2 figures},
	file = {arXiv\:1801.05661 PDF:/home/slavo/Zotero/storage/4VNBCP97/Harman et al. - 2018 - A Randomized Exchange Algorithm for Computing Opti.pdf:application/pdf;arXiv.org Snapshot:/home/slavo/Zotero/storage/3C5BLYAH/1801.html:text/html}
}

@incollection{mcmc_intro_mackay,
	address = {Dordrecht},
	series = {{NATO} {ASI} {Series}},
	title = {Introduction to {Monte} {Carlo} {Methods}},
	isbn = {978-94-011-5014-9},
	url = {https://doi.org/10.1007/978-94-011-5014-9_7},
	abstract = {This chapter describes a sequence of Monte Carlo methods: importance sampling, rejection sampling, the Metropolis method, and Gibbs sampling. For each method, we discuss whether the method is expected to be useful for high—dimensional problems such as arise in inference with graphical models. After the methods have been described, the terminology of Markov chain Monte Carlo methods is presented. The chapter concludes with a discussion of advanced methods, including methods for reducing random walk behaviour.For details of Monte Carlo methods, theorems and proofs and a full list of references, the reader is directed to Neal (1993), Gilks, Richardson and Spiegelhalter (1996), and Tanner (1996).},
	language = {en},
	urldate = {2018-12-02},
	booktitle = {Learning in {Graphical} {Models}},
	publisher = {Springer Netherlands},
	author = {Mackay, D. J. C.},
	editor = {Jordan, Michael I.},
	year = {1998},
	doi = {10.1007/978-94-011-5014-9_7},
	keywords = {Gibbs Sampling, Importance Sampling, Ising Model, Markov Chain, Monte Carlo Method},
	pages = {175--204},
	file = {Submitted Version:/home/slavo/Zotero/storage/BNHKEXFW/Mackay - 1998 - Introduction to Monte Carlo Methods.pdf:application/pdf}
}

@article{slice_convergence_roberts,
	title = {Convergence of {Slice} {Sampler} {Markov} {Chains}},
	volume = {61},
	copyright = {1999 Royal Statistical Society},
	issn = {1467-9868},
	url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/1467-9868.00198},
	doi = {10.1111/1467-9868.00198},
	abstract = {We analyse theoretical properties of the slice sampler. We find that the algorithm has extremely robust geometric ergodicity properties. For the case of just one auxiliary variable, we demonstrate that the algorithm is stochastically monotone, and we deduce analytic bounds on the total variation distance from stationarity of the method by using Foster–Lyapunov drift condition methodology.},
	language = {en},
	number = {3},
	urldate = {2018-12-10},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Roberts, Gareth O. and Rosenthal, Jeffrey S.},
	month = jan,
	year = {1999},
	keywords = {Auxiliary variables, Foster–Lyapunov drift condition, Markov chain Monte Carlo methods, Slice sampler},
	pages = {643--660},
	file = {Full Text PDF:/home/slavo/Zotero/storage/Q2MV4CWN/Roberts and Rosenthal - 1999 - Convergence of Slice Sampler Markov Chains.pdf:application/pdf;Snapshot:/home/slavo/Zotero/storage/XQDYHKED/1467-9868.html:text/html}
}